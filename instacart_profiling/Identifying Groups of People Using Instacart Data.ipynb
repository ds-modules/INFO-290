{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Info-290] Privacy & Security Lab -- Commercial Uses of Data\n",
    "\n",
    "## Prompt\n",
    "\n",
    "### Background\n",
    "In 2017, Instacart publicly released an anonymized dataset consisting of over 3 million Instacart orders with information from what was purchased and by whom (user ids) and when in the day and week purchases were made. Many retailers, including grocery stores, sell data to data brokers in order to better profile consumers. Often these purchases are linked to credit and debit cards that reveal identity. For more information, here are links [on data brokers](https://www.propublica.org/getinvolved/item/discussion-how-do-data-brokers-impact-you), [on data purchashing firms](http://www.npr.org/sections/alltechconsidered/2016/07/11/485571291/firms-are-buying-sharing-your-online-info-what-can-you-do-about-it), and [Acxiom](http://www.nytimes.com/2012/06/17/technology/acxiom-the-quiet-giant-of-consumer-database-marketing.html?pagewanted=all&_r=0&mtrref=undefined&mtrref=www.nytimes.com&mtrref=www.nytimes.com), a huge database marketer. \n",
    "\n",
    "For class today, we will work within this tool, Jupyter Notebook, to do the exercises. Each block of text in Jupyter is a \"cell.\" You can interact with these cells with the Run and Stop buttons in the toolbar above.\n",
    "\n",
    "\n",
    "### Assignment\n",
    "**Using Instacart’s data, try to profile consumers and specific groups within the dataset. For a couple of options, you could try to find a particular demographic, such as millennials, or a group a health insurance company might deem as high-risk.** Included is example analysis code that starts off by pinpointing users who have ordered any kind of potato chips in more than 50% of their orders. \n",
    "\n",
    "You're free to use whatever tools you're comfortable with. [`pandas`](https://pandas.pydata.org/pandas-docs/stable/tutorials.html) is a great library intended for fast data analysis and manipulation of large volumes; however, in this notebook, the included example of data analysis uses Berkeley's [`datascience`](http://data8.org/datascience/) module. \n",
    "\n",
    "To help clarify the content of the data, the Instacart data dictionary can be found [here](https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b). It will be extremely useful in helping you understand the data you are working with -- it gives a description of each column for each of the tables.\n",
    "\n",
    "\n",
    "### More Details\n",
    "The CSVs within `instacart_data` folder can be opened with a [`table.read_table`](http://data8.org/datascience/_autosummary/datascience.tables.Table.read_table.html) method. Examples on how to do so are below.  \n",
    "\n",
    "Here is a brief description of some elements of the more confusing (and larger!) CSVs:\n",
    "\n",
    "`orders_subset` - Each row represents one order or trip to the grocery store. `order_number` refers to whether the order was the user’s first or fifteenth. `order_dow` refers to the day of week the order was placed with Saturday as 0 and Sunday as 1. This CSV contains a subset of the original data. \n",
    "\n",
    "`order_products__prior_subset` - Each row represents one product in an order. `add_to_cart_order` refers to the order in which the product was added to the cart. \n",
    "\n",
    "On data integrity, `order_products__prior_subset` holds the data of the subset of users found in `orders_subset`. `orders_subset` has unaltered data for 10% of the unique users found in the original `orders` CSV file. Original data can be downloaded [here](https://www.instacart.com/datasets/grocery-shopping-2017). \n",
    "\n",
    "### Caveat\n",
    "When analyzing the data, especially with a large dataset, be sure to *filter* as much as possible the individual dataframes and then join as needed. In addition, when checking out what each CSV looks like, it’s recommended to use the **`show`** method, rather than loading the entire table — this might crash your notebook (e.g. `table.show(5)`). Note to run terminal commands such as *head* in Jupyter notebook, attach an exclamation point as a prefix to the command (e.g. `!head file.csv`)\n",
    "\n",
    "### To help get you going...The following box is a \"cell.\" \n",
    "\n",
    "You can cause Jupyter to execute its commands by selecting it (a blue frame will appear around it) and clicking the Run button.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the packages that we'll need for \n",
    "# our most basic functionality\n",
    "from datascience import *\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Import other libraries you would like to use below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous cell loaded the different libraries that Python needs in order to do our analysis. Now that they have been loaded, we can use the 'head' command--remember it from our first lab?\n",
    "\n",
    "Select the cell below and click run. It will show the \"head\" of the file `products.csv`.\n",
    "\n",
    "You can also pass options to head by altering the cell. Edit the cell by double clicking it. The frame will turn from blue to green. Then just add -n 20 after !head so that it reads !head -n 20 instacart_data/products.csv\n",
    "\n",
    "This will increase the number of lines displayed from 10 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head instacart_data/products.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we read in some of the csv's and store them as `Table` objects from the `datascience` package. This will incorporate more datasets for our exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to open and read in some data files within instacart_data\n",
    "orders = Table().read_table('instacart_data/orders_subset.csv')\n",
    "orders_products = Table().read_table('instacart_data/order_products__prior_subset.csv')\n",
    "products = Table().read_table('instacart_data/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a peek at the data stored in the table, we can use the `.show(n)` method on the table, where `n` is the number of rows that you want to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a small look into the first four rows of products -- highly recommended to use .show for large tables \n",
    "products.show(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analysis Example\n",
    "*If you're comfortable with data analysis and Python, feel free to skip this section and get right to analyzing!*\n",
    "\n",
    "To start with, the example seeks to find the group of Instacart users who've bought potato chips consistently. In this particular context, consistently is defined as more than 50% of a user's orders have potato chips in the cart. Using this potato-chip loving crowd, the example will then try to discover more interesting characteristics shared amongst the crowd in order to further profile and target the group. \n",
    "\n",
    "The `Table` method [`.where`](http://data8.org/datascience/_autosummary/datascience.tables.Table.where.html) is going to be extremely helpful in teasing out subsets of data. It is the primary way of filtering in `datascience`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering products to just show products that fit into the category of snacks \n",
    "snacks = products.where('department_id', 19) # Why 19? How did I know that snacks are located in department 19? \n",
    "snacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function in the following code cell filters the products table for products with names with specific phrases in them. To use the method, call the method with a case-insensitive string such as 'potato chips' and a table that contains at least the `product_name` column. The table could be products or another table filtered from products.\n",
    "\n",
    "The function returns a table that shows products with the phrase in its name. If the table is empty, then perhaps\n",
    "the phrase given was too specific. Consider trying the method again with a more general phrase. \n",
    "\n",
    "Examples of using the method:\n",
    "\n",
    "    apple_sauce = find_products_by_phrase('apple sauce', products)\n",
    "    toilet_paper = find_products_by_phrase('toilet paper', products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_products_by_phrase(phrase, table):\n",
    "    if type(phrase) != str:\n",
    "        print(\"Make sure that the phrase has either single or double quotes around it!\")\n",
    "    if 'product_name' not in table.labels:\n",
    "        print(\"Make sure that the table has a column exactly named product_name!\")\n",
    "    return table.where('product_name', lambda x: True if x.lower().find(phrase) != -1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy = find_products_by_phrase('', products)\n",
    "healthy.show(15) # Delicious..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have 196 potato chips products, we're going to take a look at the users who have ordered them.\n",
    "There are a couple of questions we need to answer before we can get to what we want. \n",
    "First question: How are we going to link what we found in `potato_chips` to the other tables? \n",
    "Second question: Which of the other tables should we be looking at? Which table first? \n",
    "\n",
    "We're going to answer the second question before the first. Because we want to have a specific group of users based on the content of their orders, we need to have a connection between orders (specifically products in each order) and users. Of the two tables that have information about orders, let's look at the column names to figure out exactly what type of information each has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders_products.show(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the `potato_chips` table has `product_id` in common with the `orders_products` table. Also, the `orders_products` table shares `order_id` with the `orders` table. \n",
    "\n",
    "To circle back to the two questions: For the second question, we're going to look at the `orders_products` and `orders` tables in that order. For the first question, we're going to find the relevant `order_id`s in `orders_products` using the `product_id`s in table `potato_chips` and then filter `orders` to only contain those relevant `order_id`s. Let's do it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the long line of code below, by using `.select`, `potato_chips` is made a smaller table with only the column `product_id`. Similarly, `orders_products` is made into a table with only two columns, `order_id` and `product_id`. \n",
    "Cutting down tables (temporarily) to only contain necessary information, then joining, decreases the \n",
    "amount of time it takes to perform the join. \n",
    "\n",
    "`orders_products_pchips` holds two columns, both of which are tied to the potato chips we found in our `potato_chips` table. The first column, `product_id`, refers to a specific kind of potato chip product. The second column, `order_id`, refers to the specific order a user placed one day. \n",
    "\n",
    "_Note: This cell will take approximately 30 seconds to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_products_pchips = orders_products.select('order_id', 'product_id')\\\n",
    "                                        .join('product_id', potato_chips.select('product_id'))\n",
    "orders_products_pchips.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `eval_set` and `days_since_prior_order` aren't of interest to us, those two columns were dropped from orders to make the table smaller upon execution of join. What results is a table arbitrarily named `pchips_orders_users` that \n",
    "connects users to their orders containing potato chips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pchips_orders_users = orders_products_pchips.join('order_id', orders.drop('eval_set', 'days_since_prior_order'))\n",
    "pchips_orders_users.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to filter `pchips_orders_users` to only contain the users who ordered some kind of potato chips at least\n",
    "in 50% of their orders that exist in our data set. \n",
    "\n",
    "To get a group of users who fit the above criterion, we group `pchips_orders_users` to obtain the count or number of \n",
    "orders by user containing potato chips. Then using [`.group`](http://data8.org/datascience/_autosummary/datascience.tables.Table.group.html) and [`.join`](http://data8.org/datascience/_autosummary/datascience.tables.Table.join.html) between orders and itself to find the max order \n",
    "number or total number of orders placed by user. We join both of these tables to get the desired user ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pchips_users = pchips_orders_users.group('user_id').relabel('count', 'pchip order count')\\\n",
    "                                .join('user_id', orders.select(['user_id', 'order_number']).group('user_id', max))\n",
    "pchips_users.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add a column, `pchip_freq_buyer`, to the new `pchips_users` table which holds `True` if that user bought potato chips in more than half of his/her/their orders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pchips_users = pchips_users.with_column('pchip_freq_buyer', \n",
    "                            pchips_users.apply(lambda count, total: True if count/total > 0.5 else False, \n",
    "                                                                   ['pchip order count', 'order_number max']))\n",
    "pchips_users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", pchips_users.where('pchip_freq_buyer', True).num_rows, \n",
    "                                                          \"users who appear to be frequent buyers of potato chips!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of how we found our crisp-lovers:\n",
    "1. Identified the `product_id` of different chips.\n",
    "2. Selected the rows in `orders_products` where a chip `product_id` occurred.\n",
    "3. Grouped the remaining rows to figure out which trips had a chip purchase.\n",
    "4. Joined with `orders` on `order_id` so that we knew which user's trips had a chip purchase.\n",
    "5. Grouped the number of chip trips for each user, so we knew their total number of potato purchases.\n",
    "6. Compared that number to the total number of transactions the user made and filtered out those with >50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Steps\n",
    "We're at the point where we have a table, pchips_freq_buyers, with which we can find all sorts of interesting characteristics about this population. At this point, hopefully you feel comfortable conducting your own analyses. If not, the following code will finish off, for now, this example. \n",
    "\n",
    "__In addition to `orders`, `orders_products`, and `products`, you have access to two other datasets (`aisles` and `departments`) located in the folder named `instacart_data`. If you wish to open those datasets, recall how we read products into a table.__\n",
    "\n",
    "<em>Some low hanging fruit for you to explore includes taking the following visualizations that we make for our chip buyers and comparing them to all of the users.<em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering pchips_orders_users to only contain users in pchips_users for which pchip_freq_buyer is True\n",
    "pchips_freq_buyers = pchips_orders_users.join('user_id', \n",
    "                                              pchips_users.where('pchip_freq_buyer', True).select('user_id'))\n",
    "pchips_freq_buyers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: What's the most popular kind of potato chips amongst chip connoisseurs? \n",
    "popular_pchip_row = pchips_freq_buyers.group('product_id').sort('count', descending=True).row(0)\n",
    "popular_pchip_id = popular_pchip_row[0]\n",
    "print(\"Most popular kind among this user group is:\", \n",
    "      products.where('product_id', popular_pchip_id).column('product_name')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some visualizations of the data findings: \n",
    "![alt text](images/example_analysis_1.png)\n",
    "#### Compare the above with this table of bestsellers based on the entire original dataset: \n",
    "![alt text](images/compare_1_a.png)\n",
    "\n",
    "![alt text](images/example_analysis_2.png)\n",
    "![alt text](images/example_analysis_3.png)\n",
    "#### Compare the above with these bar charts based on data the entire orders_subset: \n",
    "![alt text](images/compare_2.png)\n",
    "![alt text](images/compare_3.png)\n",
    "\n",
    "*The remaining code of the example is all about the visualizations shown here. Feel free to reference the code if you would like to build a horizontal bar chart or histogram.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells can be used to visualize quantitative distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram with custom title and x-label\n",
    "plt.hist(pchips_freq_buyers.column('order_dow'), color='green')\n",
    "plt.title('DoW for Orders Containing Potato Chips by Frequent Buyers of Potato Chips', y=1.08)\n",
    "plt.xlabel('DoW (0=Saturday, 1=Sunday)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pchips_freq_buyers.column('order_hour_of_day'), color='green')\n",
    "plt.title('Hour of Day for Orders Containing Potato Chips by Frequent Buyers of Potato Chips', y=1.08)\n",
    "plt.xlabel('Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What other products are ordered frequently by this specific group of people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will take a while\n",
    "# Creating a table of just user id's of frequent buyers\n",
    "freq_pchip_buyers_id = pchips_users.where('pchip_freq_buyer', True).select('user_id') \n",
    "\n",
    "# Getting the order ids \n",
    "freq_pchip_buyers_orders = orders.select(['user_id', 'order_id']).join('user_id', freq_pchip_buyers_id)\n",
    "\n",
    "# Linking the order ids to product ids \n",
    "freq_pchip_buyers_productids = orders_products.select([\"order_id\", \"product_id\"])\\\n",
    "                                              .join('order_id', freq_pchip_buyers_orders)\n",
    "    \n",
    "# Linking product ids to product names\n",
    "freq_pchip_buyers_products = freq_pchip_buyers_productids.select(['product_id'])\\\n",
    "                                                         .join('product_id', \n",
    "                                                               products.select(['product_id', 'product_name']))\n",
    "     \n",
    "# Getting the top 10 products most commonly purchased by this group of potato chip frequent buyers\n",
    "# Note that the 'count' column refers to number of orders\n",
    "freq_pchip_buyers_products = freq_pchip_buyers_products.group('product_name')\\\n",
    "                                                       .sort('count', descending=True)\\\n",
    "                                                       .take(np.arange(10))\n",
    "freq_pchip_buyers_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ypos = np.arange(10)\n",
    "ax.barh(ypos, freq_pchip_buyers_products.column('count'), color='green')\n",
    "ax.set_yticklabels(freq_pchip_buyers_products.column('product_name'))\n",
    "ax.set_yticks(ypos)\n",
    "ax.invert_yaxis() \n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title('Bestsellers Amongst the Potato-Chips Frequent Buyers', y=1.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's your turn!\n",
    "\n",
    "Feel free to copy the models from above, then make slight modifications to explore a different question. Enter code in the following cell to get started. \n",
    "\n",
    "<em>Remember: You can either click `Insert > Insert Cell Below` or press `esc` and `b` to create new cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "fig, ax = plt.subplots()\n",
    "ypos = np.arange(10)\n",
    "ax.barh(ypos, freq_pchip_buyers_products.column('count'), color='green')\n",
    "ax.set_yticklabels(freq_pchip_buyers_products.column('product_name'))\n",
    "ax.set_yticks(ypos)\n",
    "ax.invert_yaxis() \n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title('Bestsellers Amongst the Potato-Chips Frequent Buyers', y=1.08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pchips_freq_buyers.column('order_dow'), color='green')\n",
    "plt.title('DoW for Orders Containing Potato Chips by Frequent Buyers of Potato Chips', y=1.08)\n",
    "plt.xlabel('DoW (0=Saturday, 1=Sunday)')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
