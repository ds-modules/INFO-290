{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daredevil Demo - Info 290: Privacy and Security Lab\n",
    "---\n",
    "\n",
    "In this lab, we will explore the potential privacy concerns regarding location data that is supposedly anonymous. We will use a modified version of NYC Taxi data (which is made public and can be found [here](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml)) and modified NYC complaints data (found [here](https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Map-Year-to-Date-/2fra-mtpn)).\n",
    "\n",
    "Based on the fictional Marvel superhero Daredevil, we will use these two datasets to find the identity/location of Daredevil (if you do not know the background of the superhero, do not worry). While this is a seemingly trivial example, it turns out that knowing just a little bit of information can be combined with a dataset to discover much more than [intended](https://research.neustar.biz/2014/09/15/riding-with-the-stars-passenger-privacy-in-the-nyc-taxicab-dataset/).\n",
    "\n",
    "**We will look at past crime data, and knowing that Daredevil is blind and thus cannot drive himself (assume Uber does not yet exist), must use a taxi to reach crimes far from his home**\n",
    "\n",
    "For class today, we will work within this tool, Jupyter Notebook, to do the exercises. Each block of text in Jupyter is a \"cell.\" You can interact with these cells with the Run and Stop buttons in the toolbar above.\n",
    "\n",
    "If you want to go deeper, be sure to check out the [reference sheet](http://data8.org/sp18/python-reference.html) for commands, which have extensive [documentation as well](http://data8.org/datascience/). \n",
    "\n",
    "---\n",
    "\n",
    "**Topics Covered:**\n",
    "- Loading/Processing Data\n",
    "- Data Visualization\n",
    "- Combining, Exploring, and Using Data\n",
    "\n",
    "**Dependencies:**\n",
    "*if you are running this through DataHub, you do not need to worry about installing these*\n",
    "- numpy\n",
    "- datascience\n",
    "- folium\n",
    "- datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell. It imports all of the packages we will use\n",
    "!pip install -Uq folium\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import folium\n",
    "import datetime as dt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Quick note, if you ever want to know more about a certain function, you can add a **?** after a function name to pull up the docstring for the function. This will bring up a window below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table.read_table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "To start, we will load in the raw csv data (remember we are using 2 datasets) and view each one individually. Observe the column names and try to make note of what each name means. For some datasets, these names can be obscure and you will need to look directly at the source of the data to have more information about each column. However, in our case, most of the columns have column names we can easily interpret. There are a few columns that are not very clear about what they mean, but none of these columns will affect our search for the Daredevil in any significant way so we will ignore them (at least, in our demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The lines below will load the data\n",
    "taxis_raw = Table.read_table(\"Taxi_data.csv\")\n",
    "complaints_raw = Table.read_table(\"NY_complaints.csv\")\n",
    "\n",
    "# Use .show(x) function to show the first x lines of a table\n",
    "print(\"Taxi Data:\")\n",
    "taxis_raw.show(5)\n",
    "print(\"Complaints Data:\")\n",
    "complaints_raw.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data we have gives a lot of information! You can read the data dictionary to understand the taxi data columns [here](http://www.nyc.gov/html/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf) and the crime data [here](https://data.cityofnewyork.us/api/views/2fra-mtpn/files/ab329750-4a78-40f9-9c99-063525ea20e3?download=true&filename=NYPDIncidentLevelDataFootnotes.pdf).\n",
    "\n",
    "In particular, there seems to be a wealth of information in the form of times and locations. This sets up our general approach to finding our target. We will assume that for some number of the crimes committed (there would be no way for Daredevil to get to all crimes), Daredevil must have taken a taxi and was dropped off near the location of the crime. Thus, we can try to determine the taxis Daredevil took and then look at the original pickup location. However, this is complicated by the fact that we have much more data than we want and that we cannot expect Daredevil to have gotten a ride exactly to the same location and at the same exact time.\n",
    "\n",
    "## Processing our Data\n",
    "\n",
    "Before we move on to actually analyzing the data, we must process the data to be in a more usable form. Raw data is often very messy and can be a pain to work with. There can be missing values or [nans](https://en.wikipedia.org/wiki/NaN) (Not A Number) scattered throughout the dataset, and values can often be in a hard to use form. Processing the data now will make our lives much easier later.\n",
    "\n",
    "To start, we'll make the tables smaller by including only columns of interest. While this helps to focus our analysis, note that this also discards potentially useful information. If you finish the demo early and want to try some of your own analyses, feel free to use more columns than we do here (in creating the mock data, we use many more columns).\n",
    "\n",
    "For our taxi dataset, we will only select the columns for pickup/dropoff times, pickup/dropoff locations and the passenger count. For our complaints data, we will only select the level of offense (`LAW_CAT_CD`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Selecting the columns of Taxi Data according to column index\n",
    "taxis = taxis_raw.select([1,2,5,6,7,8,9])\n",
    "taxis.relabel(['lpep_pickup_datetime', 'Lpep_dropoff_datetime'], ['Pickup_dt', 'Dropoff_dt']) # renames column\n",
    "print(\"Taxi Data:\")\n",
    "taxis.show(5)\n",
    "\n",
    "# Selecting the columns of Complaints Data according to column index\n",
    "complaints = complaints_raw.select([1,2,7,9,11,21,22])\n",
    "print(\"Complaints Data:\")\n",
    "complaints.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have selected our columns, let's remove all of the rows that have a missing or null value. We will also remove zero values because some of the taxi locations have 0,0 as their coordinates (which is [clearly](https://www.google.com/maps/place/0%C2%B000'00.0%22N+0%C2%B000'00.0%22E/) not correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(t):\n",
    "    \"\"\"\n",
    "    Removes all rows with nan values checking each column\n",
    "    Note you should use this AFTER stripping the table of columns you do not need\n",
    "    so you do not remove rows when given a column without much information\n",
    "\n",
    "    Will remove most nan values but may not work with some other default missing values\n",
    "    (specifically, will not remove -999, etc. values)\n",
    "\n",
    "    Parameters:\n",
    "    t: a table whose rows with nan values you want to remove\n",
    "\n",
    "    returns a table identical to t but without rows containing nan values\n",
    "    \"\"\"\n",
    "    def checkNotnan(val):\n",
    "        if (val!=val)|(val=='nan')|(val=='NAN')|(val=='NaN')|(val==0):\n",
    "            return False\n",
    "        return True\n",
    "    for i in range(t.num_columns):\n",
    "        t = t.where(i, checkNotnan)\n",
    "    return t\n",
    "\n",
    "taxis = remove_nan(taxis)\n",
    "complaints = remove_nan(complaints)\n",
    "taxis.show(5)\n",
    "complaints.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert the format of some of the columns to be more usable. Currently, the taxi dates are in a string format and we would like to change it to a [datetime](https://docs.python.org/3/library/datetime.html) object. Effectively, we are taking the time, which is stored like any old written text, and converting it to a functional form where we can easily make comparisons to other times.\n",
    "\n",
    "To do this we will use the `apply` method to run our function for each row in the datetime columns of the taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will conveniently convert a specific format of string to a datetime\n",
    "def to_datetime(string_date):\n",
    "    '''will strip a date in a string format and return a datetime format'''\n",
    "    if type(string_date) == dt.datetime:\n",
    "        return string_date\n",
    "    return dt.datetime.strptime(string_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(\"Before:\", taxis.column(0))\n",
    "print()\n",
    "\n",
    "converted_pickup_col = taxis.apply(to_datetime, 'Pickup_dt')\n",
    "converted_dropoff_col = taxis.apply(to_datetime, 'Dropoff_dt')\n",
    "taxis = taxis.with_column('Pickup_dt', converted_pickup_col)\n",
    "taxis = taxis.with_column('Dropoff_dt', converted_dropoff_col)\n",
    "print(\"After:\", taxis.column(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will combine the dates and times of the complaints data once again by applying a function -- but now to two columns! The format of the complaints are also strings, and we want to combine them to be a single datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function we will apply to the table. Do not worry too much about the details of it\n",
    "def combine_date_time(date_string, time_string):\n",
    "    '''function that takes a date in the format of a string and a \n",
    "    time in the format of a string and then combines the two into a new datetime format'''\n",
    "    if type(date_string) == dt.date:\n",
    "        date = date_string\n",
    "    elif type(date_string) == dt.datetime:\n",
    "        date = date_string.date()\n",
    "    else:\n",
    "        date = dt.datetime.strptime(date_string, '%m/%d/%Y').date()\n",
    "        \n",
    "    if type(time_string) == dt.time:\n",
    "        time = time_string\n",
    "    elif type(date_string) == dt.datetime:\n",
    "        time = time_string.time()\n",
    "    else:\n",
    "        time = dt.datetime.strptime(time_string, '%H:%M:%S').time()\n",
    "    return dt.datetime.combine(date, time)\n",
    "\n",
    "# applies the function above\n",
    "combined_times = complaints.apply(combine_date_time, [\"CMPLNT_FR_DT\", \"CMPLNT_FR_TM\"])\n",
    "complaints = complaints.with_column(\"Complaint_dt\", combined_times)\n",
    "# drops the first two columns and reorders the table\n",
    "complaints = complaints.drop([0, 1]).select([5,3,4,0,1,2])\n",
    "complaints.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also combine the latitude/longitude data into one column so we can more easily apply functions using the `datascience` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_coordinates(latitude, longitude):\n",
    "    \"\"\"\n",
    "    returns a tuple of the given latitude and longitude\n",
    "    \"\"\"\n",
    "    return (latitude, longitude)\n",
    "\n",
    "# Apply the function above\n",
    "taxis_combined_pickup_loc = taxis.apply(combine_coordinates, ['Pickup_latitude', 'Pickup_longitude'])\n",
    "taxis_combined_dropoff_loc = taxis.apply(combine_coordinates, ['Dropoff_latitude', 'Dropoff_longitude'])\n",
    "complaints_combined_loc = complaints.apply(combine_coordinates, ['Latitude', 'Longitude'])\n",
    "\n",
    "# combine with tables and drop previous columns\n",
    "taxis = taxis.with_column(\"Pickup_location\", taxis_combined_pickup_loc)\n",
    "taxis = taxis.with_column(\"Dropoff_location\", taxis_combined_dropoff_loc)\n",
    "taxis = taxis.drop([2,3,4,5])\n",
    "\n",
    "complaints = complaints.with_column(\"Location\", complaints_combined_loc)\n",
    "complaints = complaints.drop([1,2])\n",
    "\n",
    "taxis.show(2)\n",
    "complaints.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get to move on from the boring (yet important) preprocessing of data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Before we begin trying to find our DareDevil, we will explore some of the visualization tools that we can use to easily see the data. We will be using `folium` for this purpose. You can look through the `folium` [quickstart guide](https://folium.readthedocs.io/en/latest/) or use some of the built-in helper functions we provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is the syntax to create an empty map centered at coordinates 40.7127,-74.0059\n",
    "# This is also the coordinates of NYC so you can simply use these coordinates in any other maps for this lab\n",
    "map_example = folium.Map(width=700,height=500,location=[40.7128,-74.0059], zoom_start=10)\n",
    "\n",
    "# to display the map simply type the name\n",
    "map_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to start plotting points for the lab, `folium` uses a class called Markers. You can read more documentation [here](https://folium.readthedocs.io/en/latest/quickstart.html#markers). The basics of `folium` are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new marker at coordinates (40.8436, -73.5633)\n",
    "marker_example = folium.Marker([40.72, -73.9633])\n",
    "# adds the marker to the map\n",
    "marker_example.add_to(map_example)\n",
    "# Note that there is no easy way to remove a marker once you add it to the map\n",
    "# If you want reset a map, simply run map_example = folium.Map(location=[40.7128,-74.0059])\n",
    "# in order to create a new one instead\n",
    "\n",
    "# display the map\n",
    "map_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function `addMarkers` below. This function will automatically add markers to a map from a given table assuming the table has a column called \"Location\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMarkers(fol_map, mark, location_col, color=\"blue\",icon='star',max_num=25, popup_cols=[]):\n",
    "    \"\"\"\n",
    "    adds markers to folium fol_map based on a table mark\n",
    "    Parameters:\n",
    "    fol_map: a folium.Map class that you want to add markers to\n",
    "    mark: a table containing two columns 'Latitude' and 'Longitude'\n",
    "        if these columns do not exits, defaults to using first column as latitude and 2nd as longitude\n",
    "    color: color of the marker added (default: blue)\n",
    "    icon: icon of marker added (default: star)\n",
    "    max_num: the maximum number of markers added. Use to not overload folium map (default: 25)\n",
    "    popup: the columns of the table to be included\n",
    "    returns nothing. Will modify fol_map directly\n",
    "    \"\"\"\n",
    "    if type(location_col)==str:\n",
    "        location_col = mark.column_index(location_col)\n",
    "    for i in range(mark.num_rows):\n",
    "        row = mark.row(i)\n",
    "        popup = None\n",
    "        if len(popup_cols)>0:\n",
    "            popup = \"\"\n",
    "            for col in popup_cols:\n",
    "                popup += mark.column_labels[col] + \": \" + str(row[col]) + '  '\n",
    "        folium.Marker(row[location_col],icon=folium.Icon(color=color, icon=icon), popup=popup).add_to(fol_map)\n",
    "        if (i>max_num):\n",
    "             return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add markers to the map from our taxi data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the map_example variable\n",
    "map_example = folium.Map(width=700,height=500,location=[40.7128,-74.0059], zoom_start=10)\n",
    "\n",
    "# You can also change the color and icon of the markers\n",
    "addMarkers(map_example, taxis, 'Dropoff_location', color='red', icon='cloud', popup_cols=[0,1])\n",
    "# type help(folium.Icon) to get some details of what you can put in color and icon\n",
    "\n",
    "map_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data\n",
    "\n",
    "We will be looking at the latitude and longitude data from `complaints` and `taxi` as well as the times of each of those events (so if you dropped these columns earlier, go back and change your selection so these columns are included).\n",
    "\n",
    "The rationale in our analysis is that DareDevil responds to crimes that show up in the NYPD complaints log, which lists the location of a crime. Thus, if we look at a crime where Daredevil was present, we expect to find a corresponding taxi that goes to the general area. Then, if we look at where this taxi originated from, we should be (in theory) able to find where Daredevil originates from and thus get closer to identifying him.\n",
    "\n",
    "In the real world, you can imagine that we would use a variety of ideas to begin looking for specific people or narrow our search (e.g. photos of taxis celebrities emerged out of, knowledge of where someone lives, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to display the tables\n",
    "taxis.show(1)\n",
    "complaints.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the times first. Perhaps we know that DareDevil took some taxi sometime near 11:00 pm (23:00) on January 4th. We can try to find the destination by looking at all taxi rides around that time using the `taxi` dataset. We can then write a function that checks if an event occurs within x minutes from a certain time. Then, we can use this function to select only rows from the tables that correspond to these times.\n",
    "\n",
    "We will use the `Table.where` method. One way to use this function is to give it a column name and a function that returns a boolean value (True or False) and it returns a copy of the original table, but with only the rows where the function returned True when applied to that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_11pm_jan_4(time):\n",
    "    '''\n",
    "    Returns a boolean (true or false) whether a time is 5 minutes away from January 4, 2016 at 11pm.\n",
    "    '''\n",
    "    jan_4_11_pm = dt.datetime(2016,1,4,23)\n",
    "    return abs(time - jan_4_11_pm) <= dt.timedelta(minutes=5)\n",
    "\n",
    "# Now we use the .where function to select rows from taxi where the pickup time was within 5 minutes of 11pm\n",
    "# on January 4th!\n",
    "near_11_taxis = taxis.where('Pickup_dt', near_11pm_jan_4)\n",
    "near_11_taxis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that this function is pretty restrictive. It only allows us to check a table for one specific time! Below we will define a new function that is more general and will allow us to compare two times with each other. This will prove very useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_near(time1, time2, error=5):\n",
    "    '''\n",
    "    Returns a boolean (true or false) whether 2 times are within error time of each other\n",
    "    error time is a number representing the minutes in between the two times (default 5 minutes)\n",
    "    '''\n",
    "    return abs(time1-time2) <= dt.timedelta(minutes=error)\n",
    "\n",
    "# Do not worry exactly what this line below does. It essentially creates the same \n",
    "# function we had before (and of the same name) using the more general function\n",
    "near_11pm_jan_4 = lambda x: time_near(x, dt.datetime(2016,1,4,23))\n",
    "near_11_taxis = taxis.where('Pickup_dt', near_11pm_jan_4)\n",
    "near_11_taxis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method, we can look at the time of a crime we believe Daredevil to have gone to and look at dropoff or pickup times for taxis around the same time. Below, we will create a list of tables that correspond to the first 5 rows of crimes/complaints. These tables will be all the taxis that have dropoffs within 10 minutes of the crime being reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = []\n",
    "for i in range(5):\n",
    "    time = complaints.column('Complaint_dt')[i] #gets the ith datetime of the complaint\n",
    "    temp_function = lambda x: time_near(x, time, 10)\n",
    "    table_list.append(taxis.where('Dropoff_dt', temp_function))\n",
    "table_list[4].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at location data. As with time, we can create a function to let us get all of the rows of a table with a location that is close to some certain coordinate. \n",
    "\n",
    "Before we do, we write a function that converts (roughly) the distance in km of two coordinates to make our lives easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_coord(loc1,loc2):\n",
    "    \"\"\"\n",
    "    returns distance in km between 2 coordinates\n",
    "    loc1 and loc2 should be a tuple of coordinates corresponding to the latitude and longitudes\n",
    "    of 2 locations\n",
    "    Not entirely accurate (assumes perfectly spherical earth) but works for our purposes\n",
    "    \"\"\"\n",
    "    R = 6373.0\n",
    "    lat1, lon1 = loc1\n",
    "    lat2, lon2 = loc2\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = (np.sin(dlat/2))**2 + np.cos(lat1) * np.cos(lat2) * (np.sin(dlon/2))**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we write a general function (like we did for time) to be used in `.where` call of a table. That is, we will write a function that returns True if the coordinates are within x km of another set coordinate. We use the function to then generate a table of taxis that dropped off a passenger within 1 km of the first complaint location (40.638, -73.8985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_near(loc1, loc2, error=1):\n",
    "    \"\"\"\n",
    "    returns a boolean (True or False) of whether the coordinates (lat1,lon1) and (lat2,lon2) are\n",
    "    within error km (default 1 km) of each other\n",
    "    \"\"\"\n",
    "    return dist_coord(loc1, loc2) <= error\n",
    "\n",
    "complaint_loc = complaints.column('Location')[0]\n",
    "near_first_complaint_func = lambda x: dist_near(x, complaint_loc)\n",
    "near_first_complaint_table = taxis.where('Dropoff_location', near_first_complaint_func)\n",
    "near_first_complaint_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize this! We plot the location of the complaint in red, and the locations of the taxi dropoffs in green. In addition, we plot the pickup location for each of these taxis in blue so you can see where the taxis picked up passengers who were dropped near the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distance_example_map = folium.Map(width=700,height=500,location=complaint_loc.tolist(), zoom_start=12)\n",
    "\n",
    "addMarkers(distance_example_map, near_first_complaint_table, 'Dropoff_location', color='green', popup_cols=[3,4])\n",
    "addMarkers(distance_example_map, near_first_complaint_table, 'Pickup_location', color='blue', popup_cols=[3,4])\n",
    "folium.Marker(complaint_loc, icon=folium.Icon(color='red'), popup='Complaint_location: '+str(complaint_loc)).add_to(distance_example_map)\n",
    "\n",
    "distance_example_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's try to find DareDevil! We will try to go through the complaints data and find the complaints we believe (or know) that Daredevil has gone to. Then using this, we will match the crime with a taxi that is near in time and dropoff location. Finally, we will look for common pickup locations and suspect that this is the origin location of Daredevil.\n",
    "\n",
    "For the sake of speed, we will require that the passenger count in taxis be 1 and use only January's data. We also will set the location to 1 km away and the dropoff time to be within 15 minutes of the complaint time. You are free to change any of these parameters as you see fit. In addition, if you are comfortable, try to experiment by including some of the columns we removed earlier in the pre-processing stage! \n",
    "\n",
    "*Note that some of the visualizations can be time-consuming, so we encourage you to try to find a faster way that does not need visualizations (hint: try to use the distance function on the pickup locations you get).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_err = 1\n",
    "time_err = 15\n",
    "\n",
    "felonies = complaints.where(\"LAW_CAT_CD\", \"FELONY\")\n",
    "# We create a new table with only felonies\n",
    "felonies = complaints.where(\"Complaint_dt\", \n",
    "        are.between_or_equal_to(dt.datetime(2016,1,1), dt.datetime(2016,1,31)))\n",
    "felonies.show(5)\n",
    "\n",
    "# taxi_tables will be an array of tables corresponding to the table of taxis that\n",
    "# are suspected to be related to the associated felony\n",
    "taxi_tables = []\n",
    "for row_num in range(felonies.num_rows):\n",
    "    # This should all look familiar\n",
    "    complaint_loc = felonies.column('Location')[row_num]\n",
    "    complaint_desc = felonies.column('OFNS_DESC')[row_num]\n",
    "    complaint_dt = felonies.column('Complaint_dt')[row_num]\n",
    "    \n",
    "    near_complaint_loc_func = lambda x: dist_near(x, complaint_loc, distance_err)\n",
    "    near_complaint_time_func = lambda x: time_near(x, complaint_dt, time_err)\n",
    "    \n",
    "    temp_table = taxis.where('Dropoff_location', near_complaint_loc_func)\n",
    "    temp_table = temp_table.where('Dropoff_dt', near_complaint_time_func)\n",
    "    \n",
    "    taxi_tables.append(temp_table)\n",
    "    \n",
    "\n",
    "# For visualization. Note that this can take awhile to run\n",
    "NY_map = folium.Map(width=700, height=500, location=[40.7128,-74.0059], zoom_start=10)\n",
    "\n",
    "for i in range(len(taxi_tables)):\n",
    "    table = taxi_tables[i]\n",
    "    if (table.num_rows>0):\n",
    "        complaint_loc = felonies.column('Location')[i]\n",
    "        complaint_desc = felonies.column('OFNS_DESC')[i]\n",
    "        complaint_dt = felonies.column('Complaint_dt')[i]\n",
    "        \n",
    "        felony_marker = folium.Marker(complaint_loc, icon=folium.Icon(color='red'), popup=complaint_desc)\n",
    "        felony_marker.add_to(NY_map)\n",
    "        addMarkers(NY_map, table, 'Dropoff_location', color='green', popup_cols=[3,4])\n",
    "        addMarkers(NY_map, table, 'Pickup_location', color='blue', popup_cols=[3,4])\n",
    "        \n",
    "NY_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that in the visualization, red indicates the crime, green indicates the dropoff location, and blue indicates the pickup location. Do you see anywhere that seems to be the origin of many of the blue clusters? In particular you should find that there is a small cluster of blue near the coordinates (40.76, -74.00).\n",
    "\n",
    "However, how can we be sure that this did not occur by random coincidence? There could be a variety of factors that impact the data (i.e. population, time, tourist-destination, etc). We recommend trying to explore the data yourself to find out more! You might even find more than just the location of Daredevil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Credits\n",
    "This module was created as part of the DSEP Modules team for the Spring 2018 offering of INFO 290."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
